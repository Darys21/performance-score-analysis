{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projet 5 : Analyser les ecarts de performance entre departements \n",
    "\n",
    "### Problematique metier : \n",
    "\n",
    "UNe entreprise souhaite analyser les ecarts de performance entre ses departements\n",
    "en explorant les relations entre variables qualitatives(départements, satisfaction)\n",
    "et quantitatives (salaire, temps de travail).\n",
    "\n",
    "### objectif : \n",
    "valider les differences en appliquant des tests statistiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " # importation des librairies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee_ID</th>\n",
       "      <th>Department</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Hire_Date</th>\n",
       "      <th>Years_At_Company</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Performance_Score</th>\n",
       "      <th>Monthly_Salary</th>\n",
       "      <th>Work_Hours_Per_Week</th>\n",
       "      <th>Projects_Handled</th>\n",
       "      <th>Overtime_Hours</th>\n",
       "      <th>Sick_Days</th>\n",
       "      <th>Remote_Work_Frequency</th>\n",
       "      <th>Team_Size</th>\n",
       "      <th>Training_Hours</th>\n",
       "      <th>Promotions</th>\n",
       "      <th>Employee_Satisfaction_Score</th>\n",
       "      <th>Resigned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>IT</td>\n",
       "      <td>Male</td>\n",
       "      <td>55</td>\n",
       "      <td>Specialist</td>\n",
       "      <td>2022-01-19 08:03:05.556036</td>\n",
       "      <td>2</td>\n",
       "      <td>High School</td>\n",
       "      <td>5</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Male</td>\n",
       "      <td>29</td>\n",
       "      <td>Developer</td>\n",
       "      <td>2024-04-18 08:03:05.556036</td>\n",
       "      <td>0</td>\n",
       "      <td>High School</td>\n",
       "      <td>5</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>1.72</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Male</td>\n",
       "      <td>55</td>\n",
       "      <td>Specialist</td>\n",
       "      <td>2015-10-26 08:03:05.556036</td>\n",
       "      <td>8</td>\n",
       "      <td>High School</td>\n",
       "      <td>3</td>\n",
       "      <td>5850.0</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.17</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Customer Support</td>\n",
       "      <td>Female</td>\n",
       "      <td>48</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>2016-10-22 08:03:05.556036</td>\n",
       "      <td>7</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>2</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>52</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.86</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>2021-07-23 08:03:05.556036</td>\n",
       "      <td>3</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>2</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>13</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Employee_ID        Department  Gender  Age   Job_Title  \\\n",
       "0            1                IT    Male   55  Specialist   \n",
       "1            2           Finance    Male   29   Developer   \n",
       "2            3           Finance    Male   55  Specialist   \n",
       "3            4  Customer Support  Female   48     Analyst   \n",
       "4            5       Engineering  Female   36     Analyst   \n",
       "\n",
       "                    Hire_Date  Years_At_Company Education_Level  \\\n",
       "0  2022-01-19 08:03:05.556036                 2     High School   \n",
       "1  2024-04-18 08:03:05.556036                 0     High School   \n",
       "2  2015-10-26 08:03:05.556036                 8     High School   \n",
       "3  2016-10-22 08:03:05.556036                 7        Bachelor   \n",
       "4  2021-07-23 08:03:05.556036                 3        Bachelor   \n",
       "\n",
       "   Performance_Score  Monthly_Salary  Work_Hours_Per_Week  Projects_Handled  \\\n",
       "0                  5          6750.0                   33                32   \n",
       "1                  5          7500.0                   34                34   \n",
       "2                  3          5850.0                   37                27   \n",
       "3                  2          4800.0                   52                10   \n",
       "4                  2          4800.0                   38                11   \n",
       "\n",
       "   Overtime_Hours  Sick_Days  Remote_Work_Frequency  Team_Size  \\\n",
       "0              22          2                      0         14   \n",
       "1              13         14                    100         12   \n",
       "2               6          3                     50         10   \n",
       "3              28         12                    100         10   \n",
       "4              29         13                    100         15   \n",
       "\n",
       "   Training_Hours  Promotions  Employee_Satisfaction_Score  Resigned  \n",
       "0              66           0                         2.63     False  \n",
       "1              61           2                         1.72     False  \n",
       "2               1           0                         3.17     False  \n",
       "3               0           1                         1.86     False  \n",
       "4               9           1                         1.25     False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chargement des données\n",
    "\n",
    "df = pd.read_csv(\"Extended_Employee_Performance_and_Productivity_Data.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorations des donnees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (100000, 20)\n",
      "\n",
      "Informations:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 20 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   Employee_ID                  100000 non-null  int64  \n",
      " 1   Department                   100000 non-null  object \n",
      " 2   Gender                       100000 non-null  object \n",
      " 3   Age                          100000 non-null  int64  \n",
      " 4   Job_Title                    100000 non-null  object \n",
      " 5   Hire_Date                    100000 non-null  object \n",
      " 6   Years_At_Company             100000 non-null  int64  \n",
      " 7   Education_Level              100000 non-null  object \n",
      " 8   Performance_Score            100000 non-null  int64  \n",
      " 9   Monthly_Salary               100000 non-null  float64\n",
      " 10  Work_Hours_Per_Week          100000 non-null  int64  \n",
      " 11  Projects_Handled             100000 non-null  int64  \n",
      " 12  Overtime_Hours               100000 non-null  int64  \n",
      " 13  Sick_Days                    100000 non-null  int64  \n",
      " 14  Remote_Work_Frequency        100000 non-null  int64  \n",
      " 15  Team_Size                    100000 non-null  int64  \n",
      " 16  Training_Hours               100000 non-null  int64  \n",
      " 17  Promotions                   100000 non-null  int64  \n",
      " 18  Employee_Satisfaction_Score  100000 non-null  float64\n",
      " 19  Resigned                     100000 non-null  bool   \n",
      "dtypes: bool(1), float64(2), int64(12), object(5)\n",
      "memory usage: 14.6+ MB\n",
      "None\n",
      "\n",
      "Statistiques descriptives:\n",
      "          Employee_ID Department  Gender            Age   Job_Title  \\\n",
      "count   100000.000000     100000  100000  100000.000000      100000   \n",
      "unique            NaN          9       3            NaN           7   \n",
      "top               NaN  Marketing    Male            NaN  Specialist   \n",
      "freq              NaN      11216   48031            NaN       14507   \n",
      "mean     50000.500000        NaN     NaN      41.029410         NaN   \n",
      "std      28867.657797        NaN     NaN      11.244121         NaN   \n",
      "min          1.000000        NaN     NaN      22.000000         NaN   \n",
      "25%      25000.750000        NaN     NaN      31.000000         NaN   \n",
      "50%      50000.500000        NaN     NaN      41.000000         NaN   \n",
      "75%      75000.250000        NaN     NaN      51.000000         NaN   \n",
      "max     100000.000000        NaN     NaN      60.000000         NaN   \n",
      "\n",
      "                         Hire_Date  Years_At_Company Education_Level  \\\n",
      "count                       100000     100000.000000          100000   \n",
      "unique                        3650               NaN               4   \n",
      "top     2020-09-29 08:03:05.556036               NaN        Bachelor   \n",
      "freq                            46               NaN           50041   \n",
      "mean                           NaN          4.476070             NaN   \n",
      "std                            NaN          2.869336             NaN   \n",
      "min                            NaN          0.000000             NaN   \n",
      "25%                            NaN          2.000000             NaN   \n",
      "50%                            NaN          4.000000             NaN   \n",
      "75%                            NaN          7.000000             NaN   \n",
      "max                            NaN         10.000000             NaN   \n",
      "\n",
      "        Performance_Score  Monthly_Salary  Work_Hours_Per_Week  \\\n",
      "count       100000.000000   100000.000000        100000.000000   \n",
      "unique                NaN             NaN                  NaN   \n",
      "top                   NaN             NaN                  NaN   \n",
      "freq                  NaN             NaN                  NaN   \n",
      "mean             2.995430     6403.211000            44.956950   \n",
      "std              1.414726     1372.508717             8.942003   \n",
      "min              1.000000     3850.000000            30.000000   \n",
      "25%              2.000000     5250.000000            37.000000   \n",
      "50%              3.000000     6500.000000            45.000000   \n",
      "75%              4.000000     7500.000000            53.000000   \n",
      "max              5.000000     9000.000000            60.000000   \n",
      "\n",
      "        Projects_Handled  Overtime_Hours      Sick_Days  \\\n",
      "count      100000.000000   100000.000000  100000.000000   \n",
      "unique               NaN             NaN            NaN   \n",
      "top                  NaN             NaN            NaN   \n",
      "freq                 NaN             NaN            NaN   \n",
      "mean           24.431170       14.514930       7.008550   \n",
      "std            14.469584        8.664026       4.331591   \n",
      "min             0.000000        0.000000       0.000000   \n",
      "25%            12.000000        7.000000       3.000000   \n",
      "50%            24.000000       15.000000       7.000000   \n",
      "75%            37.000000       22.000000      11.000000   \n",
      "max            49.000000       29.000000      14.000000   \n",
      "\n",
      "        Remote_Work_Frequency      Team_Size  Training_Hours     Promotions  \\\n",
      "count           100000.000000  100000.000000   100000.000000  100000.000000   \n",
      "unique                    NaN            NaN             NaN            NaN   \n",
      "top                       NaN            NaN             NaN            NaN   \n",
      "freq                      NaN            NaN             NaN            NaN   \n",
      "mean                50.090500      10.013560       49.506060       0.999720   \n",
      "std                 35.351157       5.495405       28.890383       0.815872   \n",
      "min                  0.000000       1.000000        0.000000       0.000000   \n",
      "25%                 25.000000       5.000000       25.000000       0.000000   \n",
      "50%                 50.000000      10.000000       49.000000       1.000000   \n",
      "75%                 75.000000      15.000000       75.000000       2.000000   \n",
      "max                100.000000      19.000000       99.000000       2.000000   \n",
      "\n",
      "        Employee_Satisfaction_Score Resigned  \n",
      "count                 100000.000000   100000  \n",
      "unique                          NaN        2  \n",
      "top                             NaN    False  \n",
      "freq                            NaN    89990  \n",
      "mean                       2.999088      NaN  \n",
      "std                        1.150719      NaN  \n",
      "min                        1.000000      NaN  \n",
      "25%                        2.010000      NaN  \n",
      "50%                        3.000000      NaN  \n",
      "75%                        3.990000      NaN  \n",
      "max                        5.000000      NaN  \n"
     ]
    }
   ],
   "source": [
    "# affichage des statistiques descriptives\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(\"\\nInformations:\")\n",
    "print(df.info())\n",
    "print(\"\\nStatistiques descriptives:\")\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Employee_ID', 'Department', 'Gender', 'Age', 'Job_Title', 'Hire_Date',\n",
      "       'Years_At_Company', 'Education_Level', 'Performance_Score',\n",
      "       'Monthly_Salary', 'Work_Hours_Per_Week', 'Projects_Handled',\n",
      "       'Overtime_Hours', 'Sick_Days', 'Remote_Work_Frequency', 'Team_Size',\n",
      "       'Training_Hours', 'Promotions', 'Employee_Satisfaction_Score',\n",
      "       'Resigned'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# afficher tout les noms de colonnes \n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Department  Employee_Satisfaction_Score  Performance_Score\n",
      "0                    IT                         2.63                  5\n",
      "1               Finance                         1.72                  5\n",
      "2               Finance                         3.17                  3\n",
      "3      Customer Support                         1.86                  2\n",
      "4           Engineering                         1.25                  2\n",
      "...                 ...                          ...                ...\n",
      "99995           Finance                         1.28                  4\n",
      "99996                IT                         3.48                  5\n",
      "99997        Operations                         2.60                  2\n",
      "99998                HR                         3.10                  5\n",
      "99999           Finance                         2.64                  1\n",
      "\n",
      "[100000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# afficher les colonnes : Departement , employee_satisfaction_score, performance scores \n",
    "\n",
    "print(df[[\"Department\", \"Employee_Satisfaction_Score\", \"Performance_Score\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des relations entre les variables qualitatives "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A - test de khi2\n",
    "\n",
    "en effectuant le test de khi2, on essayeras de voir si il y a une dependence entre la satisfaction des employes et leurs departements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi2: 3204.30\n",
      "p-value: 0.48\n"
     ]
    }
   ],
   "source": [
    "# test de khi2 sur  la satisfactions des employes et leurs departements\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# calcul de la matrice de contingence\n",
    "contingency_matrix = pd.crosstab(df['Department'], df['Employee_Satisfaction_Score'])\n",
    "\n",
    "# test de khi2\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_matrix)\n",
    "\n",
    "# affichage des resultats\n",
    "print(f\"Chi2: {chi2:.2f}\")\n",
    "print(f\"p-value: {p:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selon le test de khi2 observer, il n'y a pas de difference significative entre les satisfactions des employes des differents departements.La statistique chi2 3204.30 montre l'ampleur de la difference entre les frequences observées et les frequences attendues. plus la valeur est grandes, \n",
    "plus la difference l'est \n",
    "\n",
    "etant donne que la p-value est superieur a 0.05, on peut conclure que la difference n'est pas significative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B - V de cramer \n",
    "\n",
    "afin d'observer si quel pourrais etre la force assosiative entre les variables Department et Employee_Satisfaction_Score, on utilise la fonction v de cramer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient de Cramer: 0.06\n"
     ]
    }
   ],
   "source": [
    "def cramers_v(confusion_matrix):\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    return np.sqrt(phi2 / min(k - 1, r - 1))\n",
    "\n",
    "# Calcul de la matrice de contingence\n",
    "contingency_matrix = pd.crosstab(df['Department'], df['Employee_Satisfaction_Score'])\n",
    "\n",
    "# Calcul du coefficient de Cramér\n",
    "cramer_v = cramers_v(contingency_matrix)\n",
    "\n",
    "print(f\"Coefficient de Cramer: {cramer_v:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le coefficinet de cramer de 0.06 nous confirme donc que la relation entre ces deux variables est faible.\n",
    "\n",
    "le coefficient de cramer varie de 0 a 1 ou 0 indique aucune association et 1 une association parfaite "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Comparaison des moyennes ( quali - quanti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A - analyse de variance  ANOVA\n",
    "\n",
    "l'analyse de variance ANOVA est une methode statistique qui compare les moyennes entre\n",
    "plus de deux groupes (données normalement distribuées et\n",
    "variances homogènes)\n",
    "\n",
    "ce que l'on feras donc est : \n",
    "\n",
    "1-Normalité : On teste la distribution des scores pour chaque département avec le test de Shapiro-Wilk.\n",
    "\n",
    "2-Homogénéité des variances : On vérifie que les variances sont similaires entre les groupes avec le test de Levene.\n",
    "\n",
    "3-ANOVA : On réalise le test ANOVA pour comparer les moyennes.\n",
    "\n",
    "4-Post-hoc : En cas de résultat significatif, on applique le test de Tukey pour identifier précisément les différences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Employee_ID', 'Department', 'Gender', 'Age', 'Job_Title', 'Hire_Date',\n",
      "       'Years_At_Company', 'Education_Level', 'Performance_Score',\n",
      "       'Monthly_Salary', 'Work_Hours_Per_Week', 'Projects_Handled',\n",
      "       'Overtime_Hours', 'Sick_Days', 'Remote_Work_Frequency', 'Team_Size',\n",
      "       'Training_Hours', 'Promotions', 'Employee_Satisfaction_Score',\n",
      "       'Resigned'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test de normalité par Departments ===\n",
      "Department IT - Statistique = 0.8861, p-value=0.0000\n",
      " -> Distribution non conforme à la normalité\n",
      "--------------------------------------------------\n",
      "Department Finance - Statistique = 0.8881, p-value=0.0000\n",
      " -> Distribution non conforme à la normalité\n",
      "--------------------------------------------------\n",
      "Department Customer Support - Statistique = 0.8878, p-value=0.0000\n",
      " -> Distribution non conforme à la normalité\n",
      "--------------------------------------------------\n",
      "Department Engineering - Statistique = 0.8876, p-value=0.0000\n",
      " -> Distribution non conforme à la normalité\n",
      "--------------------------------------------------\n",
      "Department Marketing - Statistique = 0.8896, p-value=0.0000\n",
      " -> Distribution non conforme à la normalité\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 11131.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 11200.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 11116.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 10956.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 11216.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 10960.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 11181.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 11122.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 11118.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department HR - Statistique = 0.8881, p-value=0.0000\n",
      " -> Distribution non conforme à la normalité\n",
      "--------------------------------------------------\n",
      "Department Operations - Statistique = 0.8881, p-value=0.0000\n",
      " -> Distribution non conforme à la normalité\n",
      "--------------------------------------------------\n",
      "Department Sales - Statistique = 0.8888, p-value=0.0000\n",
      " -> Distribution non conforme à la normalité\n",
      "--------------------------------------------------\n",
      "Department Legal - Statistique = 0.8858, p-value=0.0000\n",
      " -> Distribution non conforme à la normalité\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Test d'homogénéité des variances ===\n",
      "Test de Levene - Statistique=1.0518, p-value=0.3940\n",
      "Les variances sont homogènes\n",
      "\n",
      "=== Realisation de l'analyse de variance ===\n",
      "                    df        sum_sq   mean_sq         F    PR(>F)\n",
      "C(Department)      8.0      15.33215  1.916519  0.957562  0.467323\n",
      "Residual       99991.0  200127.57936  2.001456       NaN       NaN\n",
      "\n",
      "L'ANOVA n'est pas significative (p >= 0.05). Aucun test post-hoc n'est nécessaire.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_31944\\417392745.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  anova_p_value = anova_table[\"PR(>F)\"][0]\n"
     ]
    }
   ],
   "source": [
    "# ANOVA \n",
    "from scipy.stats import f_oneway \n",
    "\n",
    "# les colonnes interessantes \n",
    "data = df[['Department', 'Performance_Score']]\n",
    "\n",
    "# liste des Departments pour iterer dessus \n",
    "Departments = data['Department'].unique()\n",
    "\n",
    "# verification de la normalite des scores pour chaque Department (test de shapiro-wilk)\n",
    "print(\"=== Test de normalité par Departments ===\")\n",
    "for dept in Departments: \n",
    "    dept_data = data[data['Department'] == dept]['Performance_Score']\n",
    "    stat, p_value = stats.shapiro(dept_data)\n",
    "    print(f\"Department {dept} - Statistique = {stat:.4f}, p-value={p_value:.4f}\")\n",
    "    # remarque sur l'interpretation \n",
    "    if p_value > 0.05:\n",
    "        print(\" -> Distribution conforme à la normalité\")\n",
    "    else: \n",
    "        print(\" -> Distribution non conforme à la normalité\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "# Verification de l'homogénéité des variances (Test de Levene)\n",
    "print(\"\\n=== Test d'homogénéité des variances ===\")\n",
    "groups = [data[data['Department'] == dept]['Performance_Score'] for dept in Departments]\n",
    "Levene_stat, levene_p = stats.levene(*groups)\n",
    "print(f\"Test de Levene - Statistique={Levene_stat:.4f}, p-value={levene_p:.4f}\")\n",
    "if levene_p > 0.05:\n",
    "    print(\"Les variances sont homogènes\")\n",
    "else: \n",
    "    print(\"Attention : Les variances diffèrent significativement entre les groupes.\")\n",
    "\n",
    "# Realisation de l'ANOVA \n",
    "print(\"\\n=== Realisation de l'analyse de variance ===\")\n",
    "model = ols('Performance_Score ~ C(Department)', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, type=2)\n",
    "print(anova_table)\n",
    "\n",
    "# Analyse post-hoc : si ANOVA est significative (inférieur au seuil de 5%)\n",
    "anova_p_value = anova_table[\"PR(>F)\"][0]\n",
    "if anova_p_value < 0.05: \n",
    "    print(\"\\nL'ANOVA est significative (p < 0.05). Passage au test post-hoc pour identifier les différences entre Departments\")\n",
    "    tukey = pairwise_tukeyhsd(endog=data['Performance_Score'], groups=data['Department'], alpha=0.05)\n",
    "    print(tukey)\n",
    "    # Affichage graphique du résultat du test de Tukey (post-hoc)\n",
    "    tukey.plot_simultaneous(figsize=(10, 6))\n",
    "    plt.title(\"Tukey HSD - Comparaison des moyennes par Department\")\n",
    "    plt.xlabel(\"Différence de Score de Performance\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nL'ANOVA n'est pas significative (p >= 0.05). Aucun test post-hoc n'est nécessaire.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interprétation rapide des résultats :\n",
    "\n",
    "1. **Test de normalité (Shapiro-Wilk)** :\n",
    "   - Pour tous les départements (HR, Operations, Sales, Legal), les p-values sont égales à 0.0000.\n",
    "   - Cela signifie que **les scores de performance ne suivent pas une distribution normale** dans chaque groupe. \n",
    "\n",
    "2. **Test d'homogénéité des variances (Levene)** :\n",
    "   - \\( p = 0.3940 \\), donc on ne rejette pas l'hypothèse nulle.\n",
    "   - **Les variances sont homogènes** entre les départements, ce qui respecte une des conditions de l'ANOVA.\n",
    "\n",
    "3. **ANOVA à un facteur** :\n",
    "   - \\( p = 0.4673 \\), donc on ne rejette pas l'hypothèse nulle.\n",
    "   - **Aucune différence significative** entre les moyennes des scores de performance des différents départements.\n",
    "   - En d'autres termes, les départements semblent avoir des performances similaires en moyenne.\n",
    "\n",
    "### Conclusion :\n",
    "Malgré l'absence de normalité, l'ANOVA a été menée car les tests ANOVA sont relativement robustes aux écarts de normalité avec de grands échantillons (ce qui est le cas ici). Cependant, comme le test n'est pas significatif, on peut conclure que les **départements n'ont pas de différence significative en termes de scores de performance**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test non paramétrique (Kruskal-Wallis)\n",
    "\n",
    "le test de Kruskal est une alternative a ANOVA et est non parametrique donc ne supposes pas de distribution specifique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test de Kruskal-Wallis ===\n",
      "Statistique de kruskal-wallis  = 7.6579, p-value = 0.4676\n",
      "Aucune difference significative n'a ete trouvee entre les departements (p >= 0.05)\n",
      "Les distributions des scores de performance sont similaires . \n"
     ]
    }
   ],
   "source": [
    "# test de krusal-wallis \n",
    "from scipy.stats import kruskal\n",
    "\n",
    "print(\"=== Test de Kruskal-Wallis ===\")\n",
    "groups = [data[data['Department'] == dept]['Performance_Score'] for dept in Departments]\n",
    "kruskal_stat, kruskal_p = kruskal(*groups)\n",
    "print(f\"Statistique de kruskal-wallis  = {kruskal_stat:.4f}, p-value = {kruskal_p:.4f}\")\n",
    "\n",
    "\n",
    "# interpretation des resultat \n",
    "if kruskal_p < 0.05:\n",
    "    print(\" Il existe une difference significative entre les departements (p < 0.05).\")\n",
    "    print(\"Les distributions des scores de performance ne sont pas identiques \")\n",
    "else: \n",
    "    print(\"Aucune difference significative n'a ete trouvee entre les departements (p >= 0.05)\")\n",
    "    print(\"Les distributions des scores de performance sont similaires . \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interprétation des résultats du test de Kruskal-Wallis :\n",
    "\n",
    "- **Statistique de Kruskal-Wallis = 7.6579**, **p-value = 0.4676**  \n",
    "- La p-value est bien supérieure à 0.05, donc on **ne rejette pas l'hypothèse nulle**.\n",
    "\n",
    "### Conclusion :\n",
    "- **Aucune différence significative** n'a été trouvée entre les départements en termes de scores de performance.\n",
    "- Cela signifie que les **distributions des scores de performance sont similaires** pour tous les départements.\n",
    "\n",
    "### Implication :\n",
    "- Les performances des employés **ne varient pas significativement selon le département**. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test pour les relations quantitatives ( quanti-quanti)\n",
    "\n",
    "En analysant les relations quantitatives, nous cherchons à démontrer comment les variations d'une variable quantitative influencent ou sont associées aux variations d'une autre variable quantitative\n",
    "\n",
    "dans notre cas pour repondre a notre probleme ce sera par exemple sur "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
